{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW8",
      "provenance": [],
      "collapsed_sections": [
        "bgte5waWKrpd",
        "vSU-TTUvNaON"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RumFnRay9oEM",
        "outputId": "68b4939f-9a6f-4de4-946c-891e92a1b37b"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 70kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 20.0MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=4cf0d3a044dd82c7703a406ca3fb194640e290d8af74a15503164a04f347154c\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68_AeFo49pEU"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftRUvQn89-yC"
      },
      "source": [
        "id='1f_9EbnywCj35EBUA32sueigxBjBJwALr'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('War and Peace by Leo Tolstoy (ru).txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpR8DQxm-IRN"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6qPAe12-Q19"
      },
      "source": [
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "2E-RdW9y-U1o",
        "outputId": "18364d7d-ffdf-4436-f662-51e747a22d19"
      },
      "source": [
        "spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c354ccfae37d:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f601954e290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQRHs49qdDeU"
      },
      "source": [
        "*`ngrok может отработать не с первого раза, повторите при необходимости.`*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6LU3RGy-Yag",
        "outputId": "970200ce-24a2-4b7a-c08f-6081d377558a"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-31 09:02:06--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 35.170.10.11, 52.200.57.5, 54.164.22.162, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|35.170.10.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.2’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  15.1MB/s    in 0.9s    \n",
            "\n",
            "2021-05-31 09:02:07 (15.1 MB/s) - ‘ngrok-stable-linux-amd64.zip.2’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n",
            "https://e84e7b621e0b.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgte5waWKrpd"
      },
      "source": [
        "###### Подсчитай кол-во слов в документе \"War and Peace by Leo Tolstoy (ru).txt\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYzYqvS-XkbI"
      },
      "source": [
        "df = spark.read.csv('./War and Peace by Leo Tolstoy (ru).txt',\n",
        "                    encoding='cp1251', sep='\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUUy-PIsgJr-"
      },
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def words(row):\n",
        "  string = unicodedata.normalize('NFKD', row[0])\n",
        "  return re.sub(r'[^\\w\\s]', '', string).split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7MMEuELbzFo",
        "outputId": "e7e6c7ae-f60e-4563-e256-3614657c9ecb"
      },
      "source": [
        "df.rdd.flatMap(words).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "472901"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSU-TTUvNaON"
      },
      "source": [
        "###### Необходимо обучить модель используя Spark MLlib (модель на ваш выбор, например Decision Tree) и получить accuracy.\n",
        "Подробнее тут: https://spark.apache.org/docs/latest/ml-classification-regression.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJgmIgCzLJTo"
      },
      "source": [
        "id='13yfAoONwq4rS5XrTv3IrcqcFcdgfvK9V'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('mnist-digits-train.txt')\n",
        "\n",
        "id='1VE_9x0LQvOJpHXbXp_RMPl3Q4wRUuOok'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('mnist-digits-test.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lPUUuQsQV4F"
      },
      "source": [
        "training = spark.read.format(\"libsvm\") \\\n",
        "  .option(\"numFeatures\", \"784\") \\\n",
        "  .load(\"./mnist-digits-train.txt\")\n",
        "test = spark.read.format(\"libsvm\") \\\n",
        "  .option(\"numFeatures\", \"784\") \\\n",
        "  .load(\"./mnist-digits-test.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EtHuUdJA3oy"
      },
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "model = dt.fit(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NLRFWTMBWLt"
      },
      "source": [
        "predictions = model.transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5kopm0xD5Fb",
        "outputId": "18f0fb59-2844-4f69-f496-a628c203c5c2"
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv-s45P8Oy8Q"
      },
      "source": [
        "###### Тут лежат данные для решения задач на sql. Необходимо написать код который формирует из данных датафреймы и используя sqlContext написать sql код с решением. Приветствуется наличие нескольких вариантов решения задачи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKMztZ2eOOrE",
        "outputId": "11142e30-ac13-48eb-8229-1cf70ac2e982"
      },
      "source": [
        "id='1kUIrskM0zNH8u71G9M1BkHjRQYxvgAvh'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('data.zip')\n",
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/regions.csv        \n",
            "  inflating: data/departments.csv    \n",
            "  inflating: data/jobs.csv           \n",
            "  inflating: data/locations.csv      \n",
            "  inflating: data/country.csv        \n",
            "  inflating: data/employees.csv      \n",
            "  inflating: data/job_history.csv    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbAE5ZtpdS3F"
      },
      "source": [
        "sqlContext = SQLContext(sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C69RJpKVdZIb"
      },
      "source": [
        "df_regions = sqlContext.read.csv('data/regions.csv', header=True, inferSchema=True, sep='\\t', quote='\"')\n",
        "df_regions.registerTempTable('regions')\n",
        "\n",
        "df_departments = sqlContext.read.csv('data/departments.csv', header=True, inferSchema=True, sep='\\t', quote='\"')\n",
        "df_departments.registerTempTable('departments')\n",
        "\n",
        "df_jobs = sqlContext.read.csv('data/jobs.csv', header=True, inferSchema=True, sep='\\t', quote='\"')\n",
        "df_jobs.registerTempTable('jobs')\n",
        "\n",
        "df_locations = sqlContext.read.csv('data/locations.csv', header=True, inferSchema=True, sep='\\t', quote='\"')\n",
        "df_locations.registerTempTable('locations')\n",
        "\n",
        "df_country = sqlContext.read.csv('data/country.csv', header=True, inferSchema=True, sep='\\t', quote='\"')\n",
        "df_country.registerTempTable('country')\n",
        "\n",
        "df_employees = sqlContext.read.csv('data/employees.csv', header=True, inferSchema=True, timestampFormat='dd.MM.yy', sep='\\t', quote='\"') \\\n",
        "  .withColumn(\"HIRE_DATE\", date_format('HIRE_DATE', \"yyyy-MM-dd\").cast('date'))\n",
        "df_employees.registerTempTable('employees')\n",
        "\n",
        "df_job_history = sqlContext.read.csv('data/job_history.csv', header=True, inferSchema=True, timestampFormat='dd.MM.yy', sep='\\t', quote='\"') \\\n",
        "  .withColumn(\"START_DATE\", date_format('START_DATE', \"yyyy-MM-dd\").cast('date')) \\\n",
        "  .withColumn(\"END_DATE\", date_format('END_DATE', \"yyyy-MM-dd\").cast('date'))\n",
        "df_job_history = df_job_history.withColumn('START_DATE',\n",
        "                                           when(year('START_DATE') > 2050,\n",
        "                                                add_months(df_job_history['START_DATE'], -1200)) \\\n",
        "                                           .otherwise(df_job_history['START_DATE']))\n",
        "df_job_history.registerTempTable('job_history')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v43K2fDAjUYb"
      },
      "source": [
        "Кто получает больше всего? Кто меньше всего?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcpM5n2yeq8f",
        "outputId": "575aae5f-d839-4ee9-9638-3a9cfac962eb"
      },
      "source": [
        "sqlContext.sql('''\n",
        "SELECT Employee_id, First_name, Last_name, Salary\n",
        "FROM employees\n",
        "WHERE salary = (SELECT MAX(salary) FROM employees)\n",
        "''').show()\n",
        "\n",
        "sqlContext.sql('''\n",
        "SELECT Employee_id, First_name, Last_name, Salary\n",
        "FROM employees\n",
        "WHERE salary = (SELECT MIN(salary) FROM employees)\n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+----------+---------+------+\n",
            "|Employee_id|First_name|Last_name|Salary|\n",
            "+-----------+----------+---------+------+\n",
            "|        100|    Steven|     King| 24000|\n",
            "+-----------+----------+---------+------+\n",
            "\n",
            "+-----------+----------+---------+------+\n",
            "|Employee_id|First_name|Last_name|Salary|\n",
            "+-----------+----------+---------+------+\n",
            "|        132|        TJ|    Olson|  2100|\n",
            "+-----------+----------+---------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg8-rkFlkMqm"
      },
      "source": [
        "Выведете топ 5 по зарплате."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMzJ_tJhnWuV",
        "outputId": "eda77267-b06e-41a7-dda4-8d1f145404d7"
      },
      "source": [
        "sqlContext.sql('''\n",
        "SELECT * FROM (\n",
        "  SELECT\n",
        "    ROW_NUMBER() OVER (ORDER BY salary DESC) as Num,\n",
        "    Employee_id,\n",
        "    first_name ||' '|| last_name as  Name,\n",
        "    Salary\n",
        "  FROM employees)\n",
        "WHERE num <= 5 \n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----------+--------------+------+\n",
            "|Num|Employee_id|          Name|Salary|\n",
            "+---+-----------+--------------+------+\n",
            "|  1|        100|   Steven King| 24000|\n",
            "|  2|        101| Neena Kochhar| 17000|\n",
            "|  3|        102|   Lex De Haan| 17000|\n",
            "|  4|        145|  John Russell| 14000|\n",
            "|  5|        146|Karen Partners| 13500|\n",
            "+---+-----------+--------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unOeubOqIvAU",
        "outputId": "1b5776ba-aafc-48ba-f244-b190f08b3db7"
      },
      "source": [
        "sqlContext.sql('''\n",
        "SELECT\n",
        "  Employee_id,\n",
        "  first_name ||' '|| last_name as  Name,\n",
        "  Salary\n",
        "FROM employees\n",
        "ORDER BY Salary DESC\n",
        "LIMIT 5\n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+--------------+------+\n",
            "|Employee_id|          Name|Salary|\n",
            "+-----------+--------------+------+\n",
            "|        100|   Steven King| 24000|\n",
            "|        101| Neena Kochhar| 17000|\n",
            "|        102|   Lex De Haan| 17000|\n",
            "|        145|  John Russell| 14000|\n",
            "|        146|Karen Partners| 13500|\n",
            "+-----------+--------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfBpDVYwkM7K"
      },
      "source": [
        "Сколько всего регионов? Сколько работников в каждом регионе?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2d2AiBknYSo",
        "outputId": "bf75e9e2-b66d-4d5c-c48b-d45893d6bc2f"
      },
      "source": [
        "sqlContext.sql('''\n",
        "SELECT COUNT (*) as num_of_regions\n",
        "FROM regions\n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+\n",
            "|num_of_regions|\n",
            "+--------------+\n",
            "|             4|\n",
            "+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnqhXAecTZ-_",
        "outputId": "29ec79bf-a322-41b5-fe7b-30a2e6e8dff3"
      },
      "source": [
        "sqlContext.sql('''\n",
        "SELECT COUNT(DISTINCT region_id) as regions_with_employees\n",
        "FROM employees e\n",
        "JOIN departments d\n",
        "  ON e.department_id = d.department_id\n",
        "JOIN locations l\n",
        "  ON d.location_id = l.location_id\n",
        "JOIN country c\n",
        "  ON l.country_id = c.country_id\n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------+\n",
            "|regions_with_employees|\n",
            "+----------------------+\n",
            "|                     2|\n",
            "+----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXMNEBczQO1H",
        "outputId": "d2940d37-7d87-49a2-d80c-64ac4484db86"
      },
      "source": [
        "sqlContext.sql('''\n",
        "SELECT region_name, COUNT(*) as num_of_employees\n",
        "FROM employees e\n",
        "JOIN departments d\n",
        "  ON e.department_id = d.department_id\n",
        "JOIN locations l\n",
        "  ON d.location_id = l.location_id\n",
        "JOIN country c\n",
        "  ON l.country_id = c.country_id\n",
        "JOIN regions r\n",
        "  ON c.region_id = r.region_id\n",
        "GROUP BY region_name\n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+----------------+\n",
            "|region_name|num_of_employees|\n",
            "+-----------+----------------+\n",
            "|     Europe|              36|\n",
            "|   Americas|              70|\n",
            "+-----------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOY2unJ8kNXz"
      },
      "source": [
        "Выведете всех работников из Китая."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lhj9GAwnZgK",
        "outputId": "95f560b5-ad2d-4c38-cb13-fd04e400b31b"
      },
      "source": [
        "sqlContext.sql('''\n",
        "SELECT employee_id, first_name ||' '|| last_name as  Name\n",
        "FROM employees e\n",
        "JOIN departments d\n",
        "  ON e.department_id = d.department_id\n",
        "JOIN locations l\n",
        "  ON d.location_id = l.location_id\n",
        "JOIN country c\n",
        "  ON l.country_id = c.country_id\n",
        "WHERE country_name = 'China'\n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+----+\n",
            "|employee_id|Name|\n",
            "+-----------+----+\n",
            "+-----------+----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Nc8F-6kNR7"
      },
      "source": [
        "Укажите самую высокооплачиваемою должность."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZNAohM-naSr",
        "outputId": "72f6d867-f324-42c3-9aa4-ac782c0ff18d"
      },
      "source": [
        "# Среди всех должностей\n",
        "sqlContext.sql('''\n",
        "SELECT job_title, min_salary, max_salary\n",
        "FROM jobs\n",
        "WHERE min_salary = (SELECT MAX(min_salary) FROM jobs)\n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+----------+----------+\n",
            "|job_title|min_salary|max_salary|\n",
            "+---------+----------+----------+\n",
            "|President|     20080|     40000|\n",
            "+---------+----------+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZXmNMN_gJkG",
        "outputId": "164e5951-5996-461d-e504-56b84ff70dd7"
      },
      "source": [
        "# Среди представленных работников\n",
        "sqlContext.sql('''\n",
        "SELECT job_title, salary\n",
        "FROM employees e\n",
        "JOIN jobs j\n",
        "  ON e.job_id = j.job_id\n",
        "WHERE salary = (SELECT MAX(salary) FROM employees)\n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+------+\n",
            "|job_title|salary|\n",
            "+---------+------+\n",
            "|President| 24000|\n",
            "+---------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzenJwUnkNL8"
      },
      "source": [
        "Выведете всех работников связанных с ИТ. Выведете их менеджеров. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFN63Mj7izrV",
        "outputId": "f6a3120e-f176-4d0b-8050-e362d3cb307d"
      },
      "source": [
        "sqlContext.sql('''\n",
        "SELECT\n",
        "  e1.employee_id,\n",
        "  e1.first_name ||' '|| e1.last_name as employee_name,\n",
        "  e2.first_name ||' '|| e2.last_name as manager_name\n",
        "FROM employees e1\n",
        "JOIN employees e2\n",
        "  ON e1.manager_id = e2.employee_id\n",
        "WHERE e1.JOB_ID = 'IT_PROG'\n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+----------------+----------------+\n",
            "|employee_id|   employee_name|    manager_name|\n",
            "+-----------+----------------+----------------+\n",
            "|        103|Alexander Hunold|     Lex De Haan|\n",
            "|        104|     Bruce Ernst|Alexander Hunold|\n",
            "|        105|    David Austin|Alexander Hunold|\n",
            "|        106| Valli Pataballa|Alexander Hunold|\n",
            "|        107|   Diana Lorentz|Alexander Hunold|\n",
            "+-----------+----------------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvpCoeYPmLTW"
      },
      "source": [
        "Выведете имя и фамилию работника, его текущую и предыдущую должности и сколько полных недель и дней прошло с момент изменения. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtEj6sYGo1Mm",
        "outputId": "a51e3178-a17a-4ba1-d3c3-6a4ea80872fe"
      },
      "source": [
        "sqlContext.sql('''\n",
        "SELECT\n",
        "  e.employee_id,\n",
        "  start_date, end_date, hire_date,\n",
        "  j1.job_title as current_job,\n",
        "  j2.job_title as previous_job\n",
        "FROM (\n",
        "  SELECT\n",
        "    employee_id, start_date, end_date, job_id,\n",
        "    ROW_NUMBER() OVER (PARTITION BY employee_id ORDER BY end_date DESC) as rn\n",
        "  FROM job_history) jh \n",
        "JOIN employees e\n",
        "  ON jh.employee_id = e.employee_id\n",
        "JOIN jobs j1\n",
        "  ON e.job_id = j1.job_id\n",
        "JOIN jobs j2\n",
        "  ON jh.job_id = j2.job_id\n",
        "WHERE rn=1\n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+----------+----------+----------+--------------------+--------------------+\n",
            "|employee_id|start_date|  end_date| hire_date|         current_job|        previous_job|\n",
            "+-----------+----------+----------+----------+--------------------+--------------------+\n",
            "|        101|2001-10-28|2005-03-15|2005-09-21|Administration Vi...|  Accounting Manager|\n",
            "|        102|2001-01-13|2006-07-24|2001-01-13|Administration Vi...|          Programmer|\n",
            "|        114|2006-03-24|2007-12-31|2002-12-07|  Purchasing Manager|         Stock Clerk|\n",
            "|        122|2007-01-01|2007-12-31|2003-05-01|       Stock Manager|         Stock Clerk|\n",
            "|        176|2007-01-01|2007-12-31|2006-03-24|Sales Representative|       Sales Manager|\n",
            "|        200|2002-07-01|2006-12-31|2003-09-17|Administration As...|   Public Accountant|\n",
            "|        201|2004-02-17|2007-12-19|2004-02-17|   Marketing Manager|Marketing Represe...|\n",
            "+-----------+----------+----------+----------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOBhGAaanC0e"
      },
      "source": [
        "Выведете уникальные телефонные номера"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05BrXyrsncKf",
        "outputId": "e2c71f65-c432-4e81-cf58-841d2dfd9ab6"
      },
      "source": [
        "sqlContext.sql('''\n",
        "SELECT DISTINCT phone_number\n",
        "FROM employees\n",
        "ORDER BY phone_number\n",
        "''').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+\n",
            "|      phone_number|\n",
            "+------------------+\n",
            "|011.44.1343.329268|\n",
            "|011.44.1343.529268|\n",
            "|011.44.1343.629268|\n",
            "|011.44.1343.729268|\n",
            "|011.44.1343.829268|\n",
            "|011.44.1343.929268|\n",
            "|011.44.1344.129268|\n",
            "|011.44.1344.345268|\n",
            "|011.44.1344.429018|\n",
            "|011.44.1344.429268|\n",
            "|011.44.1344.429278|\n",
            "|011.44.1344.467268|\n",
            "|011.44.1344.478968|\n",
            "|011.44.1344.486508|\n",
            "|011.44.1344.498718|\n",
            "|011.44.1344.619268|\n",
            "|011.44.1344.987668|\n",
            "|011.44.1345.429268|\n",
            "|011.44.1345.529268|\n",
            "|011.44.1345.629268|\n",
            "+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdf1VBv3nMR-"
      },
      "source": [
        "Есть ли сотрудники с одинаковыми фамилиями и сколько их."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apTLX1o6jy6K",
        "outputId": "e852727f-3b05-46c5-add4-ddc207f0f49a"
      },
      "source": [
        "sqlContext.sql('''\n",
        "SELECT * FROM (\n",
        "  SELECT last_name,\n",
        "  count(*) as num,\n",
        "  CONCAT_WS(', ', COLLECT_LIST(first_name || ' ' || last_name)) as full_names\n",
        "  FROM employees\n",
        "  GROUP BY last_name)\n",
        "WHERE num > 1\n",
        "''').show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+---+-----------------------------------+\n",
            "|last_name|num|full_names                         |\n",
            "+---------+---+-----------------------------------+\n",
            "|Smith    |2  |Lindsey Smith, William Smith       |\n",
            "|King     |2  |Steven King, Janette King          |\n",
            "|Cambrault|2  |Gerald Cambrault, Nanette Cambrault|\n",
            "|Taylor   |2  |Jonathon Taylor, Winston Taylor    |\n",
            "+---------+---+-----------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}